{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vista general del dataset:\n",
      "          Unnamed: 0       store_ID    day_of_week  nb_customers_on_day  \\\n",
      "count  640840.000000  640840.000000  640840.000000        640840.000000   \n",
      "mean   355990.675084     558.211348       4.000189           633.398577   \n",
      "std    205536.290268     321.878521       1.996478           464.094416   \n",
      "min         0.000000       1.000000       1.000000             0.000000   \n",
      "25%    178075.750000     280.000000       2.000000           405.000000   \n",
      "50%    355948.500000     558.000000       4.000000           609.000000   \n",
      "75%    533959.250000     837.000000       6.000000           838.000000   \n",
      "max    712044.000000    1115.000000       7.000000          5458.000000   \n",
      "\n",
      "                open      promotion  school_holiday          sales  \n",
      "count  640840.000000  640840.000000   640840.000000  640840.000000  \n",
      "mean        0.830185       0.381718        0.178472    5777.469011  \n",
      "std         0.375470       0.485808        0.382910    3851.338083  \n",
      "min         0.000000       0.000000        0.000000       0.000000  \n",
      "25%         1.000000       0.000000        0.000000    3731.000000  \n",
      "50%         1.000000       0.000000        0.000000    5746.000000  \n",
      "75%         1.000000       1.000000        0.000000    7860.000000  \n",
      "max         1.000000       1.000000        1.000000   41551.000000  \n",
      "\n",
      "Tipos de datos:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 640840 entries, 0 to 640839\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   Unnamed: 0           640840 non-null  int64 \n",
      " 1   store_ID             640840 non-null  int64 \n",
      " 2   day_of_week          640840 non-null  int64 \n",
      " 3   date                 640840 non-null  object\n",
      " 4   nb_customers_on_day  640840 non-null  int64 \n",
      " 5   open                 640840 non-null  int64 \n",
      " 6   promotion            640840 non-null  int64 \n",
      " 7   state_holiday        640840 non-null  object\n",
      " 8   school_holiday       640840 non-null  int64 \n",
      " 9   sales                640840 non-null  int64 \n",
      "dtypes: int64(8), object(2)\n",
      "memory usage: 48.9+ MB\n",
      "None\n",
      "¿La primera columna tiene valores únicos?: True\n",
      "\n",
      "Número total de valores: 640840\n",
      "Número de valores únicos: 640840\n"
     ]
    }
   ],
   "source": [
    "# Import your libraries:\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "salesDF = pd.read_csv('../data/sales.csv')\n",
    "salesDF\n",
    "\n",
    "# Challenge 1 - Explorar el Dataset\n",
    "# Examinar la vista general de los datos\n",
    "print(\"Vista general del dataset:\")\n",
    "print(salesDF.describe())\n",
    "\n",
    "# Examinar los tipos de datos\n",
    "print(\"\\nTipos de datos:\")\n",
    "print(salesDF.info())\n",
    "\n",
    "# Verificar si la primera columna tiene valores únicos\n",
    "primera_columna = salesDF.iloc[:, 0]\n",
    "es_unica = primera_columna.is_unique\n",
    "\n",
    "print(\"¿La primera columna tiene valores únicos?:\", es_unica)\n",
    "print(\"\\nNúmero total de valores:\", len(primera_columna))\n",
    "print(\"Número de valores únicos:\", primera_columna.nunique())\n",
    "\n",
    "if es_unica:\n",
    "    # Si son valores únicos, establecemos como índice\n",
    "    salesDF = salesDF.set_index(salesDF.columns[0])\n",
    "    salesDF.index.name = 'index'\n",
    "else:\n",
    "    print(\"¡Advertencia! La primera columna contiene valores duplicados y no puede usarse como índice\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 2 - Analizar Correlaciones\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Crear matriz de correlación usando columnas numéricas\n",
    "correlation_matrix = salesDF.select_dtypes(include=['int64', 'float64']).corr()\n",
    "\n",
    "# Crear heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Matriz de Correlación de Características')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 3 - Manejar Valores Faltantes\n",
    "\n",
    "# Examinar valores faltantes\n",
    "print(\"Número de valores faltantes por columna:\")\n",
    "print(salesDF.isnull().sum())\n",
    "\n",
    "# Calcular porcentaje de valores faltantes\n",
    "print(\"\\nPorcentaje de valores faltantes por columna:\")\n",
    "print((salesDF.isnull().sum() / len(salesDF)) * 100)\n",
    "\n",
    "# Eliminar columnas con más del 50% de valores faltantes\n",
    "missing_percentages = (salesDF.isnull().sum() / len(salesDF)) * 100\n",
    "columns_to_drop = missing_percentages[missing_percentages > 50].index\n",
    "sales_cleaned = salesDF.drop(columns=columns_to_drop)\n",
    "\n",
    "# Eliminar filas con valores faltantes\n",
    "sales_cleaned = sales_cleaned.dropna()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 4 - Preparar Variables Categóricas\n",
    "\n",
    "# Convertir variables categóricas a dummies\n",
    "sales_dummy = pd.get_dummies(sales_cleaned, drop_first=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 5 - Modelado y Predicción \n",
    "# (asumiendo que queremos predecir 'nb_customers_on_day')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Preparar variables\n",
    "X = sales_dummy.drop('nb_customers_on_day', axis=1)\n",
    "y = sales_dummy['nb_customers_on_day']\n",
    "\n",
    "# Dividir datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar modelo\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir y evaluar\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\nResultados del modelo:\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred)}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "print(\"\\n=== Análisis de Importancia de Features con XGBoost y RandomForest ===\")\n",
    "\n",
    "# XGBoost\n",
    "print(\"\\n--- XGBoost ---\")\n",
    "# Definir parámetros de XGBoost para regresión\n",
    "params_xgb = {\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Instanciar y entrenar modelo XGBoost\n",
    "model_xgb = xgb.XGBRegressor(**params_xgb)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "# Evaluar modelo\n",
    "print(\"\\nResultados XGBoost:\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_xgb):.4f}\")\n",
    "\n",
    "# Visualizar importancia de features con XGBoost\n",
    "plt.figure(figsize=(12, 6))\n",
    "sorted_idx = model_xgb.feature_importances_.argsort()\n",
    "plt.barh(X.columns[sorted_idx], model_xgb.feature_importances_[sorted_idx])\n",
    "plt.title('Importancia de Features - XGBoost')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "print(\"\\n--- Random Forest ---\")\n",
    "# Definir parámetros de Random Forest\n",
    "params_rf = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 3,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Instanciar y entrenar modelo Random Forest\n",
    "model_rf = RandomForestRegressor(**params_rf)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# Evaluar modelo\n",
    "print(\"\\nResultados Random Forest:\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred_rf):.4f}\")\n",
    "\n",
    "# Visualizar importancia de features con Random Forest\n",
    "plt.figure(figsize=(12, 6))\n",
    "sorted_idx = model_rf.feature_importances_.argsort()\n",
    "plt.barh(X.columns[sorted_idx], model_rf.feature_importances_[sorted_idx])\n",
    "plt.title('Importancia de Features - Random Forest')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparación de modelos\n",
    "print(\"\\n=== Comparación de Modelos ===\")\n",
    "modelos = {\n",
    "    'Regresión Lineal': (model, y_pred),\n",
    "    'XGBoost': (model_xgb, y_pred_xgb),\n",
    "    'Random Forest': (model_rf, y_pred_rf)\n",
    "}\n",
    "\n",
    "for nombre, (modelo, predicciones) in modelos.items():\n",
    "    print(f\"\\n{nombre}:\")\n",
    "    print(f\"R2 Score: {r2_score(y_test, predicciones):.4f}\")\n",
    "    print(f\"MSE: {mean_squared_error(y_test, predicciones):.4f}\")\n",
    "\n",
    "# Visualización comparativa de predicciones\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(131)\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.title('Regresión Lineal')\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.scatter(y_test, y_pred_xgb, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.title('XGBoost')\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.title('Random Forest')\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Predicciones')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
